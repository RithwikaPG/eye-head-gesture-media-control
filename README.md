# Eye & Head Gesture-Based Hands-Free Media Control System ğŸ¥ğŸ‘ï¸

A real-time **computer visionâ€“based hands-free media control system** that allows users to control YouTube playback using **eye and head gestures**.
The system is implemented using **Python, OpenCV, and MediaPipe Face Mesh**.

---

## âœ¨ Features

* ğŸ‘ï¸ Double Blink â†’ Play / Pause
* ğŸ˜´ Long Blink â†’ Mute / Unmute
* ğŸ‘€ Look Left â†’ Rewind video
* ğŸ‘€ Look Right â†’ Forward video
* ğŸ§  Head Turn (Yaw) â†’ Fast skip
* ğŸ”Š Head Tilt â†’ Volume control
* ğŸ¤– Smart Auto-Pause when face disappears or sudden distraction occurs

---

## ğŸ› ï¸ Technologies Used

* Python
* OpenCV
* MediaPipe Face Mesh
* NumPy
* Pynput

---

## ğŸ§© System Workflow

1. Capture webcam video
2. Detect facial landmarks using MediaPipe
3. Compute Eye Aspect Ratio (EAR)
4. Detect eye blink and gaze direction
5. Estimate head yaw and tilt
6. Map gestures to media control actions
7. Trigger keyboard events in real time

---

## ğŸ’» How to Run

```bash
pip install -r requirements.txt
python src/eye_head_gesture_control.py
```

âš ï¸ Keep the YouTube tab focused for keyboard controls to work.

---

## ğŸ¯ Applications

* Assistive technology
* Touchless humanâ€“computer interaction
* Smart media systems
* Computer vision research

---

## ğŸ”® Future Scope

* Gesture customization
* Multi-platform media support
* Embedded system deployment
* AI-based gesture classification

---

## ğŸ‘¤ Author

**Rithwika PG**
Robotics & Automation Engineering Student
Sahyadri College of Engineering and Management
